{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fea65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "120dc8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Crear variable categórica basada en rangos de precios\n",
    "bins = [0, 150000, 300000, float('inf')]\n",
    "labels = ['Económica', 'Intermedia', 'Cara']\n",
    "data['PriceCategory'] = pd.cut(data['SalePrice'], bins=bins, labels=labels)\n",
    "\n",
    "# Crear variables dicotómicas\n",
    "data['is_expensive'] = (data['PriceCategory'] == 'Cara').astype(int)\n",
    "data['is_medium'] = (data['PriceCategory'] == 'Intermedia').astype(int)\n",
    "data['is_economic'] = (data['PriceCategory'] == 'Económica').astype(int)\n",
    "\n",
    "# Separar características y objetivo\n",
    "X = data.drop(['SalePrice', 'PriceCategory', 'is_expensive', 'is_medium', 'is_economic'], axis=1)\n",
    "y = data['PriceCategory']  # Para modelo multiclase\n",
    "y_binary = data['is_expensive']  # Para modelo binario\n",
    "\n",
    "# Preprocesamiento\n",
    "# Convertir variables categóricas a dummy variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Manejar valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Dividir datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "# Estandarizar características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train_binary = scaler.fit_transform(X_train_binary)\n",
    "X_test_binary = scaler.transform(X_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428cd03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de validación cruzada: [0.95726496 0.95299145 0.96581197 0.9527897  0.95708155]\n",
      "Precisión media: 0.9572\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[260   8]\n",
      " [  4  20]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       268\n",
      "           1       0.71      0.83      0.77        24\n",
      "\n",
      "    accuracy                           0.96       292\n",
      "   macro avg       0.85      0.90      0.87       292\n",
      "weighted avg       0.96      0.96      0.96       292\n",
      "\n",
      "AUC-ROC: 0.9684\n",
      "\n",
      "Variables más importantes:\n",
      "                 Variable  Coeficiente\n",
      "4             OverallQual     1.232959\n",
      "27             GarageArea     0.811316\n",
      "16              GrLivArea     0.722236\n",
      "17           BsmtFullBath     0.711864\n",
      "51        LandContour_HLS     0.711052\n",
      "167          ExterQual_Ex     0.676272\n",
      "86   Neighborhood_StoneBr     0.664958\n",
      "53        LandContour_Lvl     0.646876\n",
      "19               FullBath     0.617422\n",
      "13               1stFlrSF     0.589312\n"
     ]
    }
   ],
   "source": [
    "# Crear y entrenar modelo\n",
    "log_reg_binary = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_binary.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Validación cruzada\n",
    "cv_scores = cross_val_score(log_reg_binary, X_train_binary, y_train_binary, cv=5)\n",
    "print(f\"Puntuaciones de validación cruzada: {cv_scores}\")\n",
    "print(f\"Precisión media: {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Evaluar en conjunto de prueba\n",
    "y_pred_binary = log_reg_binary.predict(X_test_binary)\n",
    "y_proba_binary = log_reg_binary.predict_proba(X_test_binary)[:, 1]\n",
    "\n",
    "# Métricas de evaluación\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary))\n",
    "print(f\"AUC-ROC: {roc_auc_score(y_test_binary, y_proba_binary):.4f}\")\n",
    "\n",
    "# Análisis de coeficientes para identificar variables importantes\n",
    "coef_df = pd.DataFrame({'Variable': X.columns, 'Coeficiente': log_reg_binary.coef_[0]})\n",
    "coef_df = coef_df.sort_values(by='Coeficiente', ascending=False)\n",
    "print(\"\\nVariables más importantes:\")\n",
    "print(coef_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
